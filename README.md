# üé• Plataforma de Transcripci√≥n de Videos a VTT

Una aplicaci√≥n web local que convierte videos de menos de 5 minutos a archivos de subt√≠tulos VTT usando OpenAI Whisper, con capacidades de traducci√≥n autom√°tica.

## ‚ú® Caracter√≠sticas

- üéØ **Transcripci√≥n precisa** con OpenAI Whisper local
- üåç **Soporte multiidioma** - Espa√±ol, Ingl√©s, Franc√©s, Alem√°n, Italiano, Portugu√©s, Ruso, Japon√©s, Coreano, Chino
- üîÑ **Traducci√≥n autom√°tica** - Transcribe en un idioma y traduce a otro usando OpenAI GPT
- üîç **Detecci√≥n autom√°tica** de idioma del video
- üì± **Interfaz responsive** y f√°cil de usar
- üîí **Procesamiento h√≠brido** - Transcripci√≥n local con Whisper, traducci√≥n via API OpenAI
- ‚ö° **R√°pido y eficiente** para videos cortos
- üìù **Formato VTT** con timestamps precisos

## üõ†Ô∏è Tecnolog√≠as

### Backend

- **Python 3.8+** con FastAPI
- **OpenAI Whisper** para transcripci√≥n local
- **OpenAI GPT API** para traducci√≥n de texto
- **MoviePy** para procesamiento de video
- **Uvicorn** como servidor ASGI

### Frontend

- **HTML5, CSS3, JavaScript** (Vanilla)
- **Responsive Design**
- **Drag & Drop** para archivos
- **Progress tracking** en tiempo real

## üìã Requisitos

- **Python 3.8 o superior**
- **FFmpeg** (requerido para procesamiento de video)
- **OpenAI API Key** (opcional, solo para traducci√≥n)
- Al menos 2GB de RAM libre
- Conexi√≥n a internet (para instalaci√≥n de Whisper y traducci√≥n)

### Instalaci√≥n de FFmpeg

FFmpeg es esencial para el funcionamiento de la aplicaci√≥n. Tienes varias opciones:

**Opci√≥n 1: Script Autom√°tico (Recomendado)**

```bash
# Ejecutar el instalador incluido
install_ffmpeg.bat
```

**Opci√≥n 2: Chocolatey (Windows)**

```bash
# Instalar Chocolatey primero (como Administrador en PowerShell):
Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))

# Luego instalar FFmpeg:
choco install ffmpeg
```

**Opci√≥n 3: Winget (Windows 10/11)**

```bash
winget install ffmpeg
```

**Opci√≥n 4: Descarga Manual**

1. Ve a https://www.gyan.dev/ffmpeg/builds/
2. Descarga "release builds" > "ffmpeg-release-essentials.zip"
3. Extrae a `C:\ffmpeg`
4. Agrega `C:\ffmpeg\bin` al PATH del sistema

### Configuraci√≥n de OpenAI API (Para Traducci√≥n)

Si deseas usar la funcionalidad de traducci√≥n, necesitas una API key de OpenAI:

1. **Obtener API Key**:

   - Ve a https://platform.openai.com/api-keys
   - Crea una cuenta o inicia sesi√≥n
   - Genera una nueva API key

2. **Configurar la API Key**:

   ```bash
   # Copia el archivo de ejemplo
   cp backend/.env.example backend/.env

   # Edita el archivo .env y agrega tu API key
   OPENAI_API_KEY=tu_api_key_aqu√≠
   ```

3. **Verificar configuraci√≥n**:
   - El archivo `.env` debe estar en la carpeta `backend/`
   - Nunca compartas tu API key p√∫blicamente
   - La traducci√≥n funcionar√° solo si la API key es v√°lida

**Nota**: La funcionalidad de transcripci√≥n funciona sin API key. Solo necesitas la API key para traducir los subt√≠tulos a otros idiomas.

## üöÄ Instalaci√≥n

### 1. Clonar o descargar el proyecto

```bash
# Si tienes git
git clone <repository-url>
cd video-transcription-platform

# O simplemente descarga y extrae los archivos
```

### 2. Configurar el Backend

```bash
# Navegar al directorio del backend
cd backend

# Crear entorno virtual (recomendado)
python -m venv venv

# Activar entorno virtual
# En Windows:
venv\Scripts\activate
# En macOS/Linux:
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

### 3. Primera ejecuci√≥n (descarga de modelo Whisper)

```bash
# Ejecutar el servidor por primera vez
python main.py
```

La primera vez que ejecutes la aplicaci√≥n, Whisper descargar√° autom√°ticamente el modelo small (~460MB). Esto puede tomar unos minutos dependiendo de tu conexi√≥n a internet.

## üéÆ Uso

### 1. Iniciar el Backend

```bash
cd backend
python main.py
```

El servidor se iniciar√° en `http://127.0.0.1:8000`

### 2. Abrir el Frontend

Tienes varias opciones:

**Opci√≥n A: Servidor HTTP simple**

```bash
cd frontend
python -m http.server 3000
```

Luego abre `http://localhost:3000`

**Opci√≥n B: Live Server (VS Code)**

- Instala la extensi√≥n "Live Server" en VS Code
- Haz clic derecho en `index.html` ‚Üí "Open with Live Server"

**Opci√≥n C: Abrir directamente**

- Simplemente abre `frontend/index.html` en tu navegador

### 3. Usar la Aplicaci√≥n

1. **Selecciona el idioma de entrada** del video (o usa detecci√≥n autom√°tica)
2. **Selecciona el idioma de salida** (opcional, para traducci√≥n)
3. **Arrastra o selecciona** tu archivo de video (m√°ximo 5 minutos)
4. **Haz clic en "Transcribir Video"**
5. **Espera** mientras se procesa:
   - Sin traducci√≥n: 1-4 minutos
   - Con traducci√≥n: 2-6 minutos (requiere API key de OpenAI)
6. **Descarga** el archivo VTT generado

#### Ejemplos de Uso:

- **Solo transcripci√≥n**: Selecciona idioma de entrada, deja idioma de salida vac√≠o
- **Transcripci√≥n + traducci√≥n**: Video en Espa√±ol ‚Üí Subt√≠tulos en Ingl√©s
- **Detecci√≥n autom√°tica**: Usa "Detectar autom√°ticamente" como idioma de entrada

## üìÅ Estructura del Proyecto

```
video-transcription-platform/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # Servidor FastAPI principal
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt     # Dependencias Python
‚îÇ   ‚îî‚îÄ‚îÄ temp_uploads/        # Archivos temporales (se crea autom√°ticamente)
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ index.html          # Interfaz principal
‚îÇ   ‚îú‚îÄ‚îÄ styles.css          # Estilos CSS
‚îÇ   ‚îî‚îÄ‚îÄ script.js           # L√≥gica JavaScript
‚îî‚îÄ‚îÄ README.md               # Este archivo
```

## üéØ Formatos Soportados

### Videos de Entrada

- **MP4** (recomendado)
- **AVI**
- **MOV**
- **MKV**
- **WebM**
- Y otros formatos soportados por FFmpeg

### Salida

- **VTT** (WebVTT) con timestamps precisos

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Cambiar Modelo de Whisper

En `backend/main.py`, l√≠nea 25:

```python
# Opciones: tiny, base, small, medium, large
model = whisper.load_model("small")  # Cambiar aqu√≠
```

**Modelos disponibles:**

- `tiny` - M√°s r√°pido, menor precisi√≥n (~39MB)
- `base` - Balance b√°sico (~140MB)
- `small` - **Por defecto** - Buena precisi√≥n (~460MB)
- `medium` - Alta precisi√≥n (~1.5GB)
- `large` - M√°xima precisi√≥n (~3GB)

### Cambiar Puerto del Backend

En `backend/main.py`, √∫ltima l√≠nea:

```python
uvicorn.run(app, host="127.0.0.1", port=8000)  # Cambiar puerto aqu√≠
```

Si cambias el puerto, tambi√©n actualiza `API_BASE_URL` en `frontend/script.js`.

## üêõ Soluci√≥n de Problemas

### Error: "No se puede conectar con el servidor"

- Verifica que el backend est√© ejecut√°ndose en http://127.0.0.1:8000
- Comprueba que no haya otro proceso usando el puerto 8000
- Revisa la consola del navegador para m√°s detalles
- Aseg√∫rate de que ambos servicios (frontend y backend) est√©n corriendo

### Error: "The system cannot find the file specified" / "FFmpeg not found"

Este es el error m√°s com√∫n. FFmpeg no est√° instalado o no est√° en el PATH:

**Soluci√≥n r√°pida:**

1. Ejecuta `install_ffmpeg.bat`
2. O instala manualmente con: `choco install ffmpeg`
3. Reinicia la terminal despu√©s de la instalaci√≥n
4. Verifica con: `ffmpeg -version`

**Si el problema persiste:**

- Reinicia tu computadora despu√©s de instalar FFmpeg
- Verifica que FFmpeg est√© en el PATH del sistema
- Prueba ejecutar `ffmpeg -version` en una nueva terminal

### Error: "El video debe durar menos de 5 minutos"

- La aplicaci√≥n tiene un l√≠mite de 5 minutos por dise√±o
- Usa un editor de video para recortar el archivo
- Verifica que el archivo no est√© corrupto

### Error: "Error en transcripci√≥n" / Baja calidad de transcripci√≥n

- Aseg√∫rate de que el audio sea claro y sin ruido de fondo
- Verifica que hayas seleccionado el idioma correcto
- Prueba con un modelo Whisper m√°s grande:
  ```python
  # En main.py, l√≠nea 25, cambia:
  model = whisper.load_model("small")  # o "medium", "large"
  ```

### Error: "Python no est√° instalado"

- Descarga Python 3.8+ desde https://python.org
- Durante la instalaci√≥n, marca "Add Python to PATH"
- Reinicia la terminal despu√©s de la instalaci√≥n

### Error: "No module named 'whisper'"

- Activa el entorno virtual: `venv\Scripts\activate.bat`
- Reinstala dependencias: `pip install -r requirements.txt`
- Si persiste: `pip install openai-whisper --upgrade`

### La aplicaci√≥n es muy lenta

- Usa un modelo Whisper m√°s peque√±o (`tiny` o `base`)
- Cierra otras aplicaciones que consuman mucha RAM
- Aseg√∫rate de tener al menos 2GB de RAM libre

### Error de CORS / Cross-Origin

- Aseg√∫rate de acceder al frontend desde http://localhost:3000
- No abras el archivo HTML directamente (file://)
- Verifica que el backend est√© corriendo en el puerto 8000

### Problemas con Traducci√≥n

**Error: "Translation failed" / "API key not configured"**

- Verifica que tengas un archivo `.env` en la carpeta `backend/`
- Aseg√∫rate de que tu API key de OpenAI sea v√°lida
- Comprueba que tengas cr√©ditos disponibles en tu cuenta de OpenAI
- El archivo `.env` debe contener: `OPENAI_API_KEY=tu_api_key_aqu√≠`

**La traducci√≥n es muy lenta**

- La traducci√≥n depende de la API de OpenAI, puede tomar tiempo adicional
- Videos m√°s largos requieren m√°s tiempo de traducci√≥n
- Verifica tu conexi√≥n a internet

**Error: "Rate limit exceeded"**

- Has excedido el l√≠mite de uso de la API de OpenAI
- Espera unos minutos antes de intentar de nuevo
- Considera actualizar tu plan de OpenAI si usas frecuentemente la traducci√≥n

## üìä Rendimiento

### Tiempos Aproximados (modelo small)

**Solo Transcripci√≥n:**

- **Video de 30 segundos**: ~20-40 segundos de procesamiento
- **Video de 1 minuto**: ~40-80 segundos de procesamiento
- **Video de 2 minutos**: ~80-160 segundos de procesamiento
- **Video de 3 minutos**: ~120-240 segundos de procesamiento
- **Video de 5 minutos**: ~200-400 segundos de procesamiento

**Transcripci√≥n + Traducci√≥n:**

- **Video de 30 segundos**: ~30-60 segundos de procesamiento
- **Video de 1 minuto**: ~60-120 segundos de procesamiento
- **Video de 2 minutos**: ~120-240 segundos de procesamiento
- **Video de 3 minutos**: ~180-360 segundos de procesamiento
- **Video de 5 minutos**: ~300-600 segundos de procesamiento

_Nota: Los tiempos de traducci√≥n dependen de la velocidad de respuesta de la API de OpenAI_

### Uso de Recursos

- **RAM**: 1-3GB durante el procesamiento
- **CPU**: Uso intensivo durante la transcripci√≥n
- **Almacenamiento**: ~500MB para modelo small + archivos temporales

## üîß API Endpoints

### GET `/`

Verificar estado del servidor

### POST `/transcribe`

Transcribir video (y opcionalmente traducir)

- **file**: Archivo de video (multipart/form-data)
- **language**: Idioma de entrada ("auto", "spanish", "english", "french", "german", "italian", "portuguese", "russian", "japanese", "korean", "chinese")
- **output_language**: (Opcional) Idioma de salida para traducci√≥n

### GET `/translation-status`

Verificar estado de la traducci√≥n (endpoint de utilidad)

### GET `/download/{filename}`

Descargar archivo VTT generado

### DELETE `/cleanup`

Limpiar archivos temporales

## üìÑ Licencia

Este proyecto es de c√≥digo abierto. Puedes usarlo, modificarlo y distribuirlo libremente.

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## üìû Soporte

Si encuentras alg√∫n problema:

1. Revisa la secci√≥n de soluci√≥n de problemas
2. Verifica los logs del servidor
3. Comprueba la consola del navegador
4. Abre un issue con detalles del error

---

**¬°Disfruta transcribiendo tus videos! üéâ**
